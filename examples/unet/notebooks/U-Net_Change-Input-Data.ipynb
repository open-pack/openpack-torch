{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b7e5bb-d393-4a1a-8406-b16be965d481",
   "metadata": {},
   "source": [
    "# U-Net | Change Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34073f0-c5b7-4750-86b3-ccbee42ca9d7",
   "metadata": {},
   "source": [
    "This is a tutorial of [OpenPack Challenge 2022](https://open-pack.github.io/challenge2022/). \n",
    "\n",
    "In this notebook, we will explain how to change the input sensor data modality for U-Net.\n",
    "[U-Net_Train-Model-and-Make-Submission-File.ipynb](./U-Net_Train-Model-and-Make-Submission-File.ipynb) uses only the acceleration data from the atr02 (left wrist).\n",
    "If you can add other sensors, you may improve the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf0d29-2d69-4376-9feb-fef6d7010d35",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-pack/openpack-torch/blob/main/examples/unet/notebooks/U-Net_Change-Input-Data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c8037-dedc-45db-9328-a2de0cfe91cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [0] Inital Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881348be-a79f-4ecf-b01c-238a4f989cab",
   "metadata": {},
   "source": [
    "### 0-1: Download Code and Install `openpack-torch` \n",
    "NOTE: You can also install `openpack-torch` from PyPI with `pip install openpack-torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f39cc-cd45-42a8-b672-6fc607520e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /content && git clone https://github.com/open-pack/openpack-torch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cab55-869f-4ee2-af87-5229628b1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd /content/openpack-torch/ && pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662a0b9-e231-4b3c-ba13-6627996e595d",
   "metadata": {},
   "source": [
    "### 0-2: Mount Your Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a60c2c-5811-475c-ac50-a792c7a58c63",
   "metadata": {},
   "source": [
    "**NOTE: If you didn't download dataset, please check this notebook [U-Net_Train-Model-and-Make-Submission-File.ipynb](./U-Net_Train-Model-and-Make-Submission-File.ipynb).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ff80e-64ae-43e0-9073-46f55f609f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "! ln -s \"/content/drive/MyDrive/Colab Notebooks/openpack/data/\" \"/content/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71436e75-af51-41ea-b5e7-6b9e7e0c3195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e262e9db-3db9-4038-b1e4-ef23f700666c",
   "metadata": {},
   "source": [
    "### 0-3: Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae8838cc-6cc5-4828-8402-fa29cc0c0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import openpack_toolkit as optk\n",
    "import openpack_torch as optorch\n",
    "import pandas as pd\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from openpack_toolkit import OPENPACK_OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7700afe9-8e59-4394-aa11-3d4589b92623",
   "metadata": {},
   "outputs": [],
   "source": [
    "optorch.configs.register_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7996697c-e4b9-40ae-b95d-88e2a65322e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r /content/openpack-torch/examples/unet/configs /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6df316-574c-4006-ae2e-5026e4c5c8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34ec3975-1cdf-420d-ba65-7f366793a6eb",
   "metadata": {},
   "source": [
    "## [1] Customize Input Data Stream (IMU Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ce647-ef82-4fd5-8bee-4c999fe6c823",
   "metadata": {},
   "source": [
    "Input modalities are controled by a **DatasetConfig** and a **DataStreamConfig**.\n",
    "With these files, only acceleration data from atr02 is loaded.\n",
    "In this section, let's change the config files to load acceleration data from 4 IMU (i.e., atr01--atr04)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b41750-d21f-439f-bec8-6451ded93355",
   "metadata": {},
   "source": [
    "**DatasetConfig**:  [configs/dataset/atr-left-wrist.yaml](https://github.com/open-pack/openpack-torch/blob/main/examples/unet/configs/dataset/atr-left-wrist.yaml)\n",
    "\n",
    "This file defines annotation data (`annotation` property), input sensor data configuration (`stream` property), data split (`split` property), and activity set (`classes` property). \n",
    "You need to change `stream` property to change input stream. The value of `stream` property is the filename in the `stream/` folder such as `configs/dataset/stream/atr-acc-left-wrist.yaml`. \n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  - annotation: activity-1s\n",
    "  - stream: atr-acc-left-wrist\n",
    "  - split: openpack-challenge-2022\n",
    "  - classes: OPENPACK_OPERATIONS\n",
    "name: \"atr-acc-left-wrist\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b90fe5-a2d5-4e49-b839-65448aa14ac3",
   "metadata": {},
   "source": [
    "**DataStreamConfig**: [configs/dataset/stream/atr-acc-left-wrist.yaml](https://github.com/open-pack/openpack-torch/blob/main/examples/unet/configs/dataset/stream/atr-acc-left-wrist.yaml)\n",
    "\n",
    "This file defines the sensor nodes and sensor type (i.e., acc, gyro, quat) and loaded by the parent config file (i.e., `configs/dataset/atr-left-wrist.yaml`).\n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  - atr-qags\n",
    "  - _self_\n",
    "name: atr-acc-left-wrist\n",
    "super_stream: atr-qags\n",
    "devices:\n",
    "  - atr02\n",
    "acc: true\n",
    "gyro: false\n",
    "quat: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364019d-9699-4633-9a81-1b58c19006b3",
   "metadata": {},
   "source": [
    "Let's start to add input modalities from here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11240a8a-f935-4921-b88d-ccbb7f4df058",
   "metadata": {},
   "source": [
    "### 1-1: Create New `DataStreamConfig`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84535376-0fb3-4d54-a4b3-2d8665d96ec2",
   "metadata": {},
   "source": [
    "Create a yaml file to `./configs/dataset/split/atr-acc-all.yaml` and copy & paste the following contents.\n",
    "\n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  - atr-qags\n",
    "  - _self_\n",
    "name: atr-acc-all # Set data stream name\n",
    "super_stream: atr-qags\n",
    "devices: # Add sensor nodes to here.\n",
    "  - atr01\n",
    "  - atr02\n",
    "  - atr03\n",
    "  - atr04\n",
    "acc: true\n",
    "gyro: false # If you want to use gyro data as well as acc, please set true.\n",
    "quat: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4eebb6-869e-4065-85c9-2e69fc2ed591",
   "metadata": {},
   "source": [
    "### 1-2: Create New `DatasetConfig`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5fb96e-1ddd-4874-8411-1726ea947080",
   "metadata": {},
   "source": [
    "Create a yaml file to `./configs/dataset/atr-acc.yaml` and copy & paste the following contents.\n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  - annotation: activity-1s\n",
    "  - stream: atr-acc-all # set filename that you created in the previous step. \n",
    "  - split: openpack-challenge-2022\n",
    "  - classes: OPENPACK_OPERATIONS\n",
    "name: \"atr-acc\" # set dataset config name. This value will be included in the log directory path.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb1294-b066-4547-9c74-5cbc253521d3",
   "metadata": {},
   "source": [
    "### 1-3: Update Root Config  (`unet.yaml`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12fcd7-f6ff-48b7-8162-d4af5c34c8b1",
   "metadata": {},
   "source": [
    "Update the dataset field in the root config file ([./config/unet.yaml](https://github.com/open-pack/openpack-torch/blob/main/examples/unet/configs/unet.yaml)).\n",
    "\n",
    "```yaml\n",
    "defaults:\n",
    "  - dataset: atr-acc #　<= EDIT HERE!! Set the filename of DatasetConfig that you created in the previous step.\n",
    "  - override hydra/job_logging: custom\n",
    "  - _self_\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ab2d1-dff4-48ab-a6fe-4239c74588d4",
   "metadata": {},
   "source": [
    "When you did the above steps, current directry is like this.\n",
    "\n",
    "```bash\n",
    "configs/\n",
    "├── dataset\n",
    "│   ├── atr-acc.yaml\n",
    "│   ├── atr-left-wrist.yaml\n",
    "│   └── stream\n",
    "│       ├── atr-acc-left-wrist.yaml\n",
    "│       └── atr-acc-all.yaml\n",
    "├── hydra\n",
    "│   └── job_logging\n",
    "│       └── custom.yaml\n",
    "└── unet.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3936aa-0878-4872-9562-d8c0b932122c",
   "metadata": {},
   "source": [
    "### 1-4: Load Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f04cc6-6903-49c6-a8d7-cdf211a113a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize_config_dir(version_base=None, config_dir=\"/content/configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        # config_name=\"unet.yaml\",\n",
    "        config_name=\"unet-tutorial2.yaml\",\n",
    "    )    \n",
    "cfg.dataset.annotation.activity_sets = dict() # Remove this attribute just for the simpler visualization.\n",
    "cfg.dataset.split = optk.configs.datasets.splits.DEBUG_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa1b8f3-4919-4aa3-8936-7f9dc9bcfca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema: ImuConfig\n",
      "name: atr-acc-all\n",
      "description: null\n",
      "super_stream: atr-qags\n",
      "path:\n",
      "  dir: ${path.openpack.rootdir}/${user.name}/atr/${device}\n",
      "  fname: ${session}.csv\n",
      "file_format: null\n",
      "frame_rate: 30\n",
      "devices:\n",
      "- atr01\n",
      "- atr02\n",
      "- atr03\n",
      "- atr04\n",
      "acc: true\n",
      "gyro: false\n",
      "quat: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg.dataset.stream))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd6ea6-98f5-4600-b84e-623730cf6aca",
   "metadata": {},
   "source": [
    "### 1-5: Load Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bfa5e93-27f2-4893-8625-ef6ffcb27fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPackImuDataModule(optorch.data.OpenPackBaseDataModule):\n",
    "    dataset_class = optorch.data.datasets.OpenPackImu\n",
    "\n",
    "    def get_kwargs_for_datasets(self, stage: Optional[str] = None) -> Dict:\n",
    "        kwargs = {\n",
    "            \"window\": self.cfg.train.window,\n",
    "            \"debug\": self.cfg.debug,\n",
    "        }\n",
    "        return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e88a3c-5f1e-4da3-a803-be631c3e946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No preprocessing is applied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 't', 'ts'])\n"
     ]
    }
   ],
   "source": [
    "datamodule = OpenPackImuDataModule(cfg)\n",
    "datamodule.setup(\"test\")\n",
    "dataloaders = datamodule.test_dataloader()\n",
    "\n",
    "batch = dataloaders[0].dataset.__getitem__(0)\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "024dbe80-7eda-4aaf-a92a-b5bfddc4c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1800, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['x'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccc766-e661-4d98-ae27-e2f5ec966287",
   "metadata": {},
   "source": [
    "The shape of input tensor is (`NUM_OF_ONPUT_CHANNELS`, `TIMESTEPS`, 1).\n",
    "So you can see that `NUM_OF_ONPUT_CHANNELS = 12` which indicates that 3 channel (x-,y-,z-axis) from 4 sensor nodes are includes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17231d3-4dcb-45fe-8bcc-79326b847941",
   "metadata": {},
   "source": [
    "### Tips\n",
    "If you create your own config file, I recommend you to store them in your google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23407afd-f004-47b4-9399-dcc658f1a059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f781c0d-6caa-4e83-a3d0-5300eb68fb0d",
   "metadata": {},
   "source": [
    "## [2] Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a91013-16c7-41bf-ab4e-60258147e306",
   "metadata": {},
   "source": [
    "You can load other sensor streams or preprocessed data by updating Dataset Class.\n",
    "If you make preprocessed dataset, please split them into sessions (e.g., \"U0101-S0100\").\n",
    "\n",
    "Here is an example to load HT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba34a193-6608-466d-b9d0-ff8fe77c553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPackImuHt(optorch.data.datasets.OpenPackImu):\n",
    "    def load_dataset(\n",
    "        self,\n",
    "        cfg: DictConfig,\n",
    "        user_session_list: Tuple[Tuple[int, int], ...],\n",
    "        window: int = None,\n",
    "        submission: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Called in ``__init__()`` and load required data.\n",
    "        Args:\n",
    "            user_session (Tuple[Tuple[str, str], ...]): _description_\n",
    "            window (int, optional): _description_. Defaults to None.\n",
    "            submission (bool, optional): _description_. Defaults to False.\n",
    "        \"\"\"\n",
    "        data, index = [], []\n",
    "        for seq_idx, (user, session) in enumerate(user_session_list):\n",
    "            with open_dict(cfg):\n",
    "                cfg.user = {\"name\": user}\n",
    "                cfg.session = session\n",
    "\n",
    "\n",
    "            \"\"\" >>>>> EDIT HERR >>>>>\n",
    "            Add function to load correspondig session! \n",
    "            \"\"\"\n",
    "            # -- IMU --\n",
    "            ts_sess, x_sess = load_imu_wrapper(cfg)\n",
    "            # -- HT & Label Printer --\n",
    "            anchor_sess = load_system_ht_wrapper(cfg, ts_sess) # function to load System/HT data. (Please implement by yourself) \n",
    "            \"\"\" <<<<<<<<<<<<<<<<<<<<<\n",
    "            \"\"\"\n",
    "\n",
    "            # -- annotation --\n",
    "            label = load_annot_wrapper(cfg, ts_sess, submission, self.classes)\n",
    "\n",
    "            data.append({\n",
    "                \"user\": user,\n",
    "                \"session\": session,\n",
    "                \"data\": x_sess,\n",
    "                \"data/anchor\": anchor_sess.astype(x_sess.dtype), # << ADD loaded sequence!!\n",
    "                \"label\": label,\n",
    "                \"unixtime\": ts_sess,\n",
    "            })\n",
    "\n",
    "            seq_len = ts_sess.shape[0]\n",
    "            index += [dict(seq=seq_idx, seg=seg_idx, pos=pos)\n",
    "                      for seg_idx, pos in enumerate(range(0, seq_len, window))]\n",
    "        self.data = data\n",
    "        self.index = tuple(index)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        s = (\n",
    "            \"OpenPackImuHt(\"\n",
    "            f\"index={len(self.index)}, \"\n",
    "            f\"num_sequence={len(self.data)}, \"\n",
    "            f\"submission={self.submission} \"\n",
    "            f\"random_crop={self.random_crop}\"\n",
    "            \")\"\n",
    "        )\n",
    "        return s\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict:\n",
    "        seq_idx, seg_idx = self.index[index][\"seq\"], self.index[index][\"seg\"]\n",
    "        seq_dict = self.data[seq_idx]\n",
    "        seq_len = seq_dict[\"data\"].shape[1]\n",
    "\n",
    "        head, tail, pad_tail = get_segment_head_and_tail(\n",
    "            seg_idx, self.window, seq_len, self.random_crop)\n",
    "\n",
    "        # extract a segment\n",
    "        x = seq_dict[\"data\"][:, head:tail, np.newaxis]\n",
    "        x_anchor = seq_dict[\"data/anchor\"][:, head:tail, np.newaxis] # << ADD\n",
    "        t = seq_dict[\"label\"][head:tail]\n",
    "        ts = seq_dict[\"unixtime\"][head:tail]\n",
    "\n",
    "        if pad_tail > 0:\n",
    "            x = np.pad(x, [(0, 0), (0, pad_tail), (0, 0)],\n",
    "                       mode=\"constant\", constant_values=0)\n",
    "            x_anchor = np.pad(x_anchor, [(0, 0), (0, pad_tail), (0, 0)],\n",
    "                              mode=\"constant\", constant_values=0)  # << ADD\n",
    "            t = np.pad(t, [(0, pad_tail)], mode=\"constant\",\n",
    "                       constant_values=self.classes.get_ignore_class_index())\n",
    "            ts = np.pad(ts, [(0, pad_tail)],\n",
    "                        mode=\"constant\", constant_values=ts[-1])\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        x_anchor = torch.from_numpy(x_anchor) # << ADD\n",
    "        t = torch.from_numpy(t)\n",
    "        ts = torch.from_numpy(ts)\n",
    "        return {\"x\": x, \"x/anchor\": x_anchor, \"t\": t, \"ts\": ts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13aff24a-6686-4079-9f75-2ef7d9eed1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPackImuHtDataModule(optorch.data.OpenPackBaseDataModule):\n",
    "    # NOTE: Change Dataset Class\n",
    "    dataset_class = OpenPackImuHt\n",
    "\n",
    "    def get_kwargs_for_datasets(self, stage: Optional[str] = None) -> Dict:\n",
    "        kwargs = {\n",
    "            \"window\": self.cfg.train.window,\n",
    "            \"debug\": self.cfg.debug,\n",
    "        }\n",
    "        return kwargs\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        super().setup(stage=stage)\n",
    "        if self.op_train is not None:\n",
    "            self.op_train.random_crop = True\n",
    "            logger.debug(\n",
    "                f\"enable random_crop in training dataset: {self.op_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c152f-1559-4d70-9171-ee5e3aed78df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d489d7cc-ce12-472f-8331-5cf2d664d192",
   "metadata": {},
   "source": [
    "## [3] Apply Preprocessing (Online Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388c8db-f81f-4984-a214-20ea829a53b2",
   "metadata": {},
   "source": [
    "Dataset class has `preprocessing()` method and you can implement only preprocessing logi here.\n",
    "\n",
    "Here is an example to normalize acceleration data ([-3G, +3G]) into [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acbd6918-fd37-4059-be90-5cb25db61392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPackImuNormalize(optorch.data.datasets.OpenPackImu):\n",
    "    \"\"\"Dataset class for IMU + HT.\n",
    "    \"\"\"\n",
    "    def preprocessing(self) -> None:\n",
    "        \"\"\"\n",
    "        * Normalize [-3G, +3G] into [0, 1].\n",
    "        \"\"\"\n",
    "        # NOTE: Normalize ACC data. ([-3G, +3G] -> [0, 1])\n",
    "        # NOTE: Described in Appendix Sec.3.2.\n",
    "        for seq_dict in self.data:\n",
    "            x = seq_dict.get(\"data\")\n",
    "            x = np.clip(x, -3, +3)\n",
    "            x = (x + 3.) / 6.\n",
    "            seq_dict[\"data\"] = x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d500c2-c111-487f-943f-3a8af5e31fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
