{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ecdf0d29-2d69-4376-9feb-fef6d7010d35",
      "metadata": {
        "id": "ecdf0d29-2d69-4376-9feb-fef6d7010d35"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-pack/openpack-torch/blob/main/examples/notebooks/U-Net_Change-Input-Data.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b7e5bb-d393-4a1a-8406-b16be965d481",
      "metadata": {
        "id": "54b7e5bb-d393-4a1a-8406-b16be965d481"
      },
      "source": [
        "# U-Net | Change Input Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34073f0-c5b7-4750-86b3-ccbee42ca9d7",
      "metadata": {
        "id": "c34073f0-c5b7-4750-86b3-ccbee42ca9d7"
      },
      "source": [
        "This is a tutorial of [OpenPack Challenge 2022](https://open-pack.github.io/challenge2022/).\n",
        "\n",
        "In this notebook, we will explain how to change the input sensor data modality for U-Net.\n",
        "[U-Net_Train-Model-and-Make-Submission-File.ipynb](./U-Net_Train-Model-and-Make-Submission-File.ipynb) uses only the acceleration data from the atr02 (left wrist).\n",
        "If you can add other sensors, you may improve the scores."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7c8037-dedc-45db-9328-a2de0cfe91cd",
      "metadata": {
        "tags": [],
        "id": "ad7c8037-dedc-45db-9328-a2de0cfe91cd"
      },
      "source": [
        "## [0] Inital Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "881348be-a79f-4ecf-b01c-238a4f989cab",
      "metadata": {
        "id": "881348be-a79f-4ecf-b01c-238a4f989cab"
      },
      "source": [
        "### 0-1: Download Code and Install `openpack-torch`\n",
        "NOTE: You can also install `openpack-torch` from PyPI with `pip install openpack-torch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "704f39cc-cd45-42a8-b672-6fc607520e01",
      "metadata": {
        "id": "704f39cc-cd45-42a8-b672-6fc607520e01",
        "outputId": "0c02e49c-f27b-4a06-a990-85e5684ce6b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'openpack-torch'...\n",
            "remote: Enumerating objects: 1249, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 1249 (delta 68), reused 59 (delta 59), pack-reused 1149\u001b[K\n",
            "Receiving objects: 100% (1249/1249), 55.56 MiB | 23.18 MiB/s, done.\n",
            "Resolving deltas: 100% (511/511), done.\n",
            "Updating files: 100% (163/163), done.\n"
          ]
        }
      ],
      "source": [
        "! cd /content && git clone https://github.com/open-pack/openpack-torch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e75cab55-869f-4ee2-af87-5229628b1ca0",
      "metadata": {
        "id": "e75cab55-869f-4ee2-af87-5229628b1ca0",
        "outputId": "2467af80-0276-4fa4-a96a-82af02ecbd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openpack-torch\n",
            "  Downloading openpack_torch-1.0.1-py3-none-any.whl (29 kB)\n",
            "Collecting hydra-core<2.0.0,>=1.3.1 (from openpack-torch)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from openpack-torch) (1.23.5)\n",
            "Collecting omegaconf<3.0.0,>=2.3.0 (from openpack-torch)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openpack-toolkit==1.0.1 (from openpack-torch)\n",
            "  Downloading openpack_toolkit-1.0.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from openpack-torch) (1.5.3)\n",
            "Collecting pytorch-lightning<3.0,>=2.1 (from openpack-torch)\n",
            "  Downloading pytorch_lightning-2.1.4-py3-none-any.whl (778 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from openpack-torch) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from openpack-torch) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from openpack-toolkit==1.0.1->openpack-torch) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from openpack-toolkit==1.0.1->openpack-torch) (1.11.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<2.0.0,>=1.3.1->openpack-torch)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core<2.0.0,>=1.3.1->openpack-torch) (23.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0.0,>=2.3.0->openpack-torch) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.2->openpack-torch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.5.2->openpack-torch) (2023.4)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3.0,>=2.1->openpack-torch) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning<3.0,>=2.1->openpack-torch)\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3.0,>=2.1->openpack-torch) (4.5.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning<3.0,>=2.1->openpack-torch)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.1->openpack-torch) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.1->openpack-torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.1->openpack-torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.1->openpack-torch) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.1->openpack-torch) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.2->openpack-torch) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->openpack-toolkit==1.0.1->openpack-torch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.0->openpack-toolkit==1.0.1->openpack-torch) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.1->openpack-torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0,>=2.1->openpack-torch) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning<3.0,>=2.1->openpack-torch) (2023.11.17)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=e58eeb5aa0fd5bc0611916233734fad10a6f468d3540655fa78906e5fdf30ad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, lightning-utilities, hydra-core, torchmetrics, openpack-toolkit, pytorch-lightning, openpack-torch\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 lightning-utilities-0.10.1 omegaconf-2.3.0 openpack-toolkit-1.0.1 openpack-torch-1.0.1 pytorch-lightning-2.1.4 torchmetrics-1.3.0.post0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install openpack-torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a662a0b9-e231-4b3c-ba13-6627996e595d",
      "metadata": {
        "id": "a662a0b9-e231-4b3c-ba13-6627996e595d"
      },
      "source": [
        "### 0-2: Mount Your Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a60c2c-5811-475c-ac50-a792c7a58c63",
      "metadata": {
        "id": "06a60c2c-5811-475c-ac50-a792c7a58c63"
      },
      "source": [
        "Follow the instruction of [Tutorial - Download OpenPack Dataset to Google Drive.ipynb](https://colab.research.google.com/drive/1YOnegl9L6UnlfermwJpevWLQ43anwwGd?usp=sharing) to download OpenPack Dataset (v1.0.0) to your Google Drive.\n",
        "\n",
        "After you finish downloading the datasets, mount your Google Drive to this notebook and create a shortcut to `/content/data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ad2ff80e-64ae-43e0-9073-46f55f609f6f",
      "metadata": {
        "id": "ad2ff80e-64ae-43e0-9073-46f55f609f6f",
        "outputId": "078dbe78-8f9e-4f71-bcab-d3299e80bf47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! ln -s \"/content/drive/MyDrive/Colab Notebooks/openpack/data/\" \"/content/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71436e75-af51-41ea-b5e7-6b9e7e0c3195",
      "metadata": {
        "id": "71436e75-af51-41ea-b5e7-6b9e7e0c3195"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e262e9db-3db9-4038-b1e4-ef23f700666c",
      "metadata": {
        "id": "e262e9db-3db9-4038-b1e4-ef23f700666c"
      },
      "source": [
        "### 0-3: Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ae8838cc-6cc5-4828-8402-fa29cc0c0d09",
      "metadata": {
        "id": "ae8838cc-6cc5-4828-8402-fa29cc0c0d09"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import hydra\n",
        "import numpy as np\n",
        "import openpack_toolkit as optk\n",
        "import openpack_torch as optorch\n",
        "import pandas as pd\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "from openpack_toolkit import OPENPACK_OPERATIONS, ActSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7700afe9-8e59-4394-aa11-3d4589b92623",
      "metadata": {
        "id": "7700afe9-8e59-4394-aa11-3d4589b92623"
      },
      "outputs": [],
      "source": [
        "optorch.configs.register_configs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7996697c-e4b9-40ae-b95d-88e2a65322e7",
      "metadata": {
        "id": "7996697c-e4b9-40ae-b95d-88e2a65322e7"
      },
      "outputs": [],
      "source": [
        "! cp -r /content/openpack-torch/examples/configs /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8d6df316-574c-4006-ae2e-5026e4c5c8d6",
      "metadata": {
        "id": "8d6df316-574c-4006-ae2e-5026e4c5c8d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "34ec3975-1cdf-420d-ba65-7f366793a6eb",
      "metadata": {
        "id": "34ec3975-1cdf-420d-ba65-7f366793a6eb"
      },
      "source": [
        "## [1] Customize Input Data Stream (IMU Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f1ce647-ef82-4fd5-8bee-4c999fe6c823",
      "metadata": {
        "id": "2f1ce647-ef82-4fd5-8bee-4c999fe6c823"
      },
      "source": [
        "Input modalities are controled by a **DatasetConfig** and a **DataStreamConfig**.\n",
        "With these files, only acceleration data from atr02 is loaded.\n",
        "In this section, let's change the config files to load acceleration data from 4 IMU (i.e., atr01--atr04)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b41750-d21f-439f-bec8-6451ded93355",
      "metadata": {
        "id": "b2b41750-d21f-439f-bec8-6451ded93355"
      },
      "source": [
        "**DatasetConfig**:  [configs/dataset/atr-left-wrist.yaml](https://github.com/open-pack/openpack-torch/blob/main/examples/unet/configs/dataset/atr-left-wrist.yaml)\n",
        "\n",
        "This file defines annotation data (`annotation` property), input sensor data configuration (`stream` property), data split (`split` property), and activity set (`classes` property).\n",
        "You need to change `stream` property to change input stream. The value of `stream` property is the filename in the `stream/` folder such as `configs/dataset/stream/atr-acc-left-wrist.yaml`.\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - annotation: activity-1s\n",
        "  - stream: atr-acc-left-wrist\n",
        "  - split: openpack-challenge-2022\n",
        "  - classes: OPENPACK_OPERATIONS\n",
        "name: \"atr-acc-left-wrist\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b90fe5-a2d5-4e49-b839-65448aa14ac3",
      "metadata": {
        "id": "93b90fe5-a2d5-4e49-b839-65448aa14ac3"
      },
      "source": [
        "**DataStreamConfig**: [configs/dataset/stream/atr-acc-left-wrist.yaml](https://github.com/open-pack/openpack-torch/blob/main/examples/unet/configs/dataset/stream/atr-acc-left-wrist.yaml)\n",
        "\n",
        "This file defines the sensor nodes and sensor type (i.e., acc, gyro, quat) and loaded by the parent config file (i.e., `configs/dataset/atr-left-wrist.yaml`).\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - atr-qags\n",
        "  - _self_\n",
        "name: atr-acc-left-wrist\n",
        "super_stream: atr-qags\n",
        "devices:\n",
        "  - atr02\n",
        "acc: true\n",
        "gyro: false\n",
        "quat: false\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5364019d-9699-4633-9a81-1b58c19006b3",
      "metadata": {
        "id": "5364019d-9699-4633-9a81-1b58c19006b3"
      },
      "source": [
        "Let's start to add input modalities from here."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11240a8a-f935-4921-b88d-ccbb7f4df058",
      "metadata": {
        "id": "11240a8a-f935-4921-b88d-ccbb7f4df058"
      },
      "source": [
        "### 1-1: Create New `DataStreamConfig`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84535376-0fb3-4d54-a4b3-2d8665d96ec2",
      "metadata": {
        "id": "84535376-0fb3-4d54-a4b3-2d8665d96ec2"
      },
      "source": [
        "Create a yaml file to `./configs/dataset/split/atr-acc-all.yaml` and copy & paste the following contents.\n",
        "\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - atr-qags\n",
        "  - _self_\n",
        "name: atr-acc-all # Set data stream name\n",
        "super_stream: atr-qags\n",
        "devices: # Add sensor nodes to here.\n",
        "  - atr01\n",
        "  - atr02\n",
        "  - atr03\n",
        "  - atr04\n",
        "acc: true\n",
        "gyro: false # If you want to use gyro data as well as acc, please set true.\n",
        "quat: false\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd4eebb6-869e-4065-85c9-2e69fc2ed591",
      "metadata": {
        "id": "cd4eebb6-869e-4065-85c9-2e69fc2ed591"
      },
      "source": [
        "### 1-2: Create New `DatasetConfig`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e5fb96e-1ddd-4874-8411-1726ea947080",
      "metadata": {
        "id": "0e5fb96e-1ddd-4874-8411-1726ea947080"
      },
      "source": [
        "Create a yaml file to `./configs/dataset/atr-acc.yaml` and copy & paste the following contents.\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - annotation: activity-1s\n",
        "  - stream: atr-acc-all # set filename that you created in the previous step.\n",
        "  - split: openpack-challenge-2022\n",
        "  - classes: OPENPACK_OPERATIONS\n",
        "name: \"atr-acc\" # set dataset config name. This value will be included in the log directory path.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91eb1294-b066-4547-9c74-5cbc253521d3",
      "metadata": {
        "id": "91eb1294-b066-4547-9c74-5cbc253521d3"
      },
      "source": [
        "### 1-3: Update Root Config  (`unet.yaml`)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f12fcd7-f6ff-48b7-8162-d4af5c34c8b1",
      "metadata": {
        "id": "4f12fcd7-f6ff-48b7-8162-d4af5c34c8b1"
      },
      "source": [
        "Update the dataset field in the root config file ([./config/unet.yaml](https://github.com/open-pack/openpack-torch/blob/main/examples/unet/configs/unet.yaml)).\n",
        "\n",
        "```yaml\n",
        "defaults:\n",
        "  - dataset: atr-acc # <= EDIT HERE!! Set the filename of DatasetConfig that you created in the previous step.\n",
        "  - override hydra/job_logging: custom\n",
        "  - _self_\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "865ab2d1-dff4-48ab-a6fe-4239c74588d4",
      "metadata": {
        "id": "865ab2d1-dff4-48ab-a6fe-4239c74588d4"
      },
      "source": [
        "When you did the above steps, current directry is like this.\n",
        "\n",
        "```bash\n",
        "configs/\n",
        "├── dataset\n",
        "│   ├── atr-acc.yaml\n",
        "│   ├── atr-left-wrist.yaml\n",
        "│   └── stream\n",
        "│       ├── atr-acc-left-wrist.yaml\n",
        "│       └── atr-acc-all.yaml\n",
        "├── hydra\n",
        "│   └── job_logging\n",
        "│       └── custom.yaml\n",
        "└── unet.yaml\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3936aa-0878-4872-9562-d8c0b932122c",
      "metadata": {
        "id": "0b3936aa-0878-4872-9562-d8c0b932122c"
      },
      "source": [
        "### 1-4: Load Config Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f04cc6-6903-49c6-a8d7-cdf211a113a4",
      "metadata": {
        "id": "99f04cc6-6903-49c6-a8d7-cdf211a113a4"
      },
      "outputs": [],
      "source": [
        "with hydra.initialize_config_dir(version_base=None, config_dir=\"/content/configs\"):\n",
        "    cfg = hydra.compose(\n",
        "        # config_name=\"unet.yaml\",\n",
        "        config_name=\"unet-tutorial2.yaml\",\n",
        "    )\n",
        "cfg.dataset.annotation.activity_sets = dict() # Remove this attribute just for the simpler visualization.\n",
        "cfg.dataset.split = optk.configs.datasets.splits.DEBUG_SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa1b8f3-4919-4aa3-8936-7f9dc9bcfca2",
      "metadata": {
        "id": "4aa1b8f3-4919-4aa3-8936-7f9dc9bcfca2",
        "outputId": "d26971a8-55d5-46d5-deaf-cf5c188827db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "schema: ImuConfig\n",
            "name: atr-acc-all\n",
            "description: null\n",
            "super_stream: atr-qags\n",
            "path:\n",
            "  dir: ${path.openpack.rootdir}/${user.name}/atr/${device}\n",
            "  fname: ${session}.csv\n",
            "file_format: null\n",
            "frame_rate: 30\n",
            "devices:\n",
            "- atr01\n",
            "- atr02\n",
            "- atr03\n",
            "- atr04\n",
            "acc: true\n",
            "gyro: false\n",
            "quat: false\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(OmegaConf.to_yaml(cfg.dataset.stream))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02bd6ea6-98f5-4600-b84e-623730cf6aca",
      "metadata": {
        "id": "02bd6ea6-98f5-4600-b84e-623730cf6aca"
      },
      "source": [
        "### 1-5: Load Dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bfa5e93-27f2-4893-8625-ef6ffcb27fb2",
      "metadata": {
        "id": "7bfa5e93-27f2-4893-8625-ef6ffcb27fb2"
      },
      "outputs": [],
      "source": [
        "class OpenPackImuDataModule(optorch.data.OpenPackBaseDataModule):\n",
        "    dataset_class = optorch.data.datasets.OpenPackImu\n",
        "\n",
        "    def get_kwargs_for_datasets(self, stage: Optional[str] = None) -> Dict:\n",
        "        kwargs = {\n",
        "            \"window\": self.cfg.train.window,\n",
        "            \"debug\": self.cfg.debug,\n",
        "        }\n",
        "        return kwargs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e88a3c-5f1e-4da3-a803-be631c3e946a",
      "metadata": {
        "id": "f1e88a3c-5f1e-4da3-a803-be631c3e946a",
        "outputId": "a4ae2f52-1821-48b4-9244-b2700f9d2f60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No preprocessing is applied.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['x', 't', 'ts'])\n"
          ]
        }
      ],
      "source": [
        "datamodule = OpenPackImuDataModule(cfg)\n",
        "datamodule.setup(\"test\")\n",
        "dataloaders = datamodule.test_dataloader()\n",
        "\n",
        "batch = dataloaders[0].dataset.__getitem__(0)\n",
        "print(batch.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024dbe80-7eda-4aaf-a92a-b5bfddc4c40e",
      "metadata": {
        "id": "024dbe80-7eda-4aaf-a92a-b5bfddc4c40e",
        "outputId": "fcb34ca6-bac6-460a-adf5-f6e16427c07a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12, 1800, 1])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['x'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ccc766-e661-4d98-ae27-e2f5ec966287",
      "metadata": {
        "id": "a4ccc766-e661-4d98-ae27-e2f5ec966287"
      },
      "source": [
        "The shape of input tensor is (`NUM_OF_ONPUT_CHANNELS`, `TIMESTEPS`, 1).\n",
        "So you can see that `NUM_OF_ONPUT_CHANNELS = 12` which indicates that 3 channel (x-,y-,z-axis) from 4 sensor nodes are includes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17231d3-4dcb-45fe-8bcc-79326b847941",
      "metadata": {
        "id": "a17231d3-4dcb-45fe-8bcc-79326b847941"
      },
      "source": [
        "### Tips\n",
        "If you create your own config file, I recommend you to store them in your google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23407afd-f004-47b4-9399-dcc658f1a059",
      "metadata": {
        "id": "23407afd-f004-47b4-9399-dcc658f1a059"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9f781c0d-6caa-4e83-a3d0-5300eb68fb0d",
      "metadata": {
        "id": "9f781c0d-6caa-4e83-a3d0-5300eb68fb0d"
      },
      "source": [
        "## [2] Load Preprocessed Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4a91013-16c7-41bf-ab4e-60258147e306",
      "metadata": {
        "id": "a4a91013-16c7-41bf-ab4e-60258147e306"
      },
      "source": [
        "You can load other sensor streams or preprocessed data by updating Dataset Class.\n",
        "If you make preprocessed dataset, please split them into sessions (e.g., \"U0101-S0100\").\n",
        "\n",
        "Here is an example to load HT data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba34a193-6608-466d-b9d0-ff8fe77c553c",
      "metadata": {
        "id": "ba34a193-6608-466d-b9d0-ff8fe77c553c"
      },
      "outputs": [],
      "source": [
        "class OpenPackImuHt(optorch.data.datasets.OpenPackImu):\n",
        "    def load_dataset(\n",
        "        self,\n",
        "        cfg: DictConfig,\n",
        "        user_session_list: Tuple[Tuple[int, int], ...],\n",
        "        window: int = None,\n",
        "        submission: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"Called in ``__init__()`` and load required data.\n",
        "        Args:\n",
        "            user_session (Tuple[Tuple[str, str], ...]): _description_\n",
        "            window (int, optional): _description_. Defaults to None.\n",
        "            submission (bool, optional): _description_. Defaults to False.\n",
        "        \"\"\"\n",
        "        data, index = [], []\n",
        "        for seq_idx, (user, session) in enumerate(user_session_list):\n",
        "            with open_dict(cfg):\n",
        "                cfg.user = {\"name\": user}\n",
        "                cfg.session = session\n",
        "\n",
        "\n",
        "            \"\"\" >>>>> EDIT HERR >>>>>\n",
        "            Add function to load correspondig session!\n",
        "            \"\"\"\n",
        "            # -- IMU --\n",
        "            ts_sess, x_sess = load_imu_wrapper(cfg)\n",
        "            # -- HT & Label Printer --\n",
        "            anchor_sess = load_system_ht_wrapper(cfg, ts_sess) # function to load System/HT data. (Please implement by yourself)\n",
        "            \"\"\" <<<<<<<<<<<<<<<<<<<<<\n",
        "            \"\"\"\n",
        "\n",
        "            # -- annotation --\n",
        "            label = load_annot_wrapper(cfg, ts_sess, submission, self.classes)\n",
        "\n",
        "            data.append({\n",
        "                \"user\": user,\n",
        "                \"session\": session,\n",
        "                \"data\": x_sess,\n",
        "                \"data/anchor\": anchor_sess.astype(x_sess.dtype), # << ADD loaded sequence!!\n",
        "                \"label\": label,\n",
        "                \"unixtime\": ts_sess,\n",
        "            })\n",
        "\n",
        "            seq_len = ts_sess.shape[0]\n",
        "            index += [dict(seq=seq_idx, seg=seg_idx, pos=pos)\n",
        "                      for seg_idx, pos in enumerate(range(0, seq_len, window))]\n",
        "        self.data = data\n",
        "        self.index = tuple(index)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        s = (\n",
        "            \"OpenPackImuHt(\"\n",
        "            f\"index={len(self.index)}, \"\n",
        "            f\"num_sequence={len(self.data)}, \"\n",
        "            f\"submission={self.submission} \"\n",
        "            f\"random_crop={self.random_crop}\"\n",
        "            \")\"\n",
        "        )\n",
        "        return s\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict:\n",
        "        seq_idx, seg_idx = self.index[index][\"seq\"], self.index[index][\"seg\"]\n",
        "        seq_dict = self.data[seq_idx]\n",
        "        seq_len = seq_dict[\"data\"].shape[1]\n",
        "\n",
        "        head, tail, pad_tail = get_segment_head_and_tail(\n",
        "            seg_idx, self.window, seq_len, self.random_crop)\n",
        "\n",
        "        # extract a segment\n",
        "        x = seq_dict[\"data\"][:, head:tail, np.newaxis]\n",
        "        x_anchor = seq_dict[\"data/anchor\"][:, head:tail, np.newaxis] # << ADD\n",
        "        t = seq_dict[\"label\"][head:tail]\n",
        "        ts = seq_dict[\"unixtime\"][head:tail]\n",
        "\n",
        "        if pad_tail > 0:\n",
        "            x = np.pad(x, [(0, 0), (0, pad_tail), (0, 0)],\n",
        "                       mode=\"constant\", constant_values=0)\n",
        "            x_anchor = np.pad(x_anchor, [(0, 0), (0, pad_tail), (0, 0)],\n",
        "                              mode=\"constant\", constant_values=0)  # << ADD\n",
        "            t = np.pad(t, [(0, pad_tail)], mode=\"constant\",\n",
        "                       constant_values=self.classes.get_ignore_class_index())\n",
        "            ts = np.pad(ts, [(0, pad_tail)],\n",
        "                        mode=\"constant\", constant_values=ts[-1])\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        x_anchor = torch.from_numpy(x_anchor) # << ADD\n",
        "        t = torch.from_numpy(t)\n",
        "        ts = torch.from_numpy(ts)\n",
        "        return {\"x\": x, \"x/anchor\": x_anchor, \"t\": t, \"ts\": ts}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13aff24a-6686-4079-9f75-2ef7d9eed1ba",
      "metadata": {
        "id": "13aff24a-6686-4079-9f75-2ef7d9eed1ba"
      },
      "outputs": [],
      "source": [
        "class OpenPackImuHtDataModule(optorch.data.OpenPackBaseDataModule):\n",
        "    # NOTE: Change Dataset Class\n",
        "    dataset_class = OpenPackImuHt\n",
        "\n",
        "    def get_kwargs_for_datasets(self, stage: Optional[str] = None) -> Dict:\n",
        "        kwargs = {\n",
        "            \"window\": self.cfg.train.window,\n",
        "            \"debug\": self.cfg.debug,\n",
        "        }\n",
        "        return kwargs\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None):\n",
        "        super().setup(stage=stage)\n",
        "        if self.op_train is not None:\n",
        "            self.op_train.random_crop = True\n",
        "            logger.debug(\n",
        "                f\"enable random_crop in training dataset: {self.op_train}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd0c152f-1559-4d70-9171-ee5e3aed78df",
      "metadata": {
        "id": "cd0c152f-1559-4d70-9171-ee5e3aed78df"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d489d7cc-ce12-472f-8331-5cf2d664d192",
      "metadata": {
        "id": "d489d7cc-ce12-472f-8331-5cf2d664d192"
      },
      "source": [
        "## [3] Apply Preprocessing (Online Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3388c8db-f81f-4984-a214-20ea829a53b2",
      "metadata": {
        "id": "3388c8db-f81f-4984-a214-20ea829a53b2"
      },
      "source": [
        "Dataset class has `preprocessing()` method and you can implement only preprocessing logi here.\n",
        "\n",
        "Here is an example to normalize acceleration data ([-3G, +3G]) into [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acbd6918-fd37-4059-be90-5cb25db61392",
      "metadata": {
        "id": "acbd6918-fd37-4059-be90-5cb25db61392"
      },
      "outputs": [],
      "source": [
        "class OpenPackImuNormalize(optorch.data.datasets.OpenPackImu):\n",
        "    \"\"\"Dataset class for IMU + HT.\n",
        "    \"\"\"\n",
        "    def preprocessing(self) -> None:\n",
        "        \"\"\"\n",
        "        * Normalize [-3G, +3G] into [0, 1].\n",
        "        \"\"\"\n",
        "        # NOTE: Normalize ACC data. ([-3G, +3G] -> [0, 1])\n",
        "        # NOTE: Described in Appendix Sec.3.2.\n",
        "        for seq_dict in self.data:\n",
        "            x = seq_dict.get(\"data\")\n",
        "            x = np.clip(x, -3, +3)\n",
        "            x = (x + 3.) / 6.\n",
        "            seq_dict[\"data\"] = x\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d500c2-c111-487f-943f-3a8af5e31fd1",
      "metadata": {
        "id": "f5d500c2-c111-487f-943f-3a8af5e31fd1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}